{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install dgl-cu90 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.py\n",
    "from tqdm import trange\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from logger import Logger\n",
    "from modules.model_m import GeneratorFullModel, DiscriminatorFullModel\n",
    "\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from sync_batchnorm import DataParallelWithCallback\n",
    "\n",
    "from frames_dataset import DatasetRepeater\n",
    "\n",
    "#run.py \n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import os, sys\n",
    "import yaml\n",
    "from argparse import ArgumentParser\n",
    "from time import gmtime, strftime\n",
    "from shutil import copy\n",
    "\n",
    "from frames_dataset import FramesDataset\n",
    "\n",
    "from modules.generator import OcclusionAwareGenerator\n",
    "from modules.discriminator import MultiScaleDiscriminator\n",
    "from modules.keypoint_detector import KPDetector\n",
    "\n",
    "import torch\n",
    "\n",
    "#from train import train\n",
    "from reconstruction import reconstruction\n",
    "from animate import animate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from modules.graphattn_a1 import MultiHeadAttention\n",
    "from visualization_a import *\n",
    "from demo import make_animation\n",
    "from visualization_kp_a import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_ubyte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(opt2, generator, kp_detector, discriminator, \n",
    "               model_no=1):\n",
    "    checkpoint_path = opt2.checkpoints[model_no]\n",
    "\n",
    "    #checkpoint.seed(0)\n",
    "    if opt2.cpu:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "    if not \"dense_motion_network.kp_variance\" in checkpoint['generator']:\n",
    "        checkpoint['generator'][\"dense_motion_network.kp_variance\"] = torch.tensor([0.01])\n",
    "    else:\n",
    "        print(\"kp_variance: \", checkpoint['generator'][\"dense_motion_network.kp_variance\"])\n",
    "        \n",
    "    generator.load_state_dict(checkpoint['generator'])#,strict=False\n",
    "    kp_detector.load_state_dict(checkpoint['kp_detector'])\n",
    "    discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "    if 'kp_refiner' in checkpoint: \n",
    "        kp_refiner = MultiHeadAttention(2,2,1,alpha=0.3)\n",
    "        kp_refiner.load_state_dict(checkpoint['kp_refiner'])\n",
    "    else:\n",
    "        kp_refiner = None\n",
    "    return generator, kp_detector, discriminator, kp_refiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(opt2, model_no=0):\n",
    "    print(\"model_no: \", model_no)\n",
    "    class opt:\n",
    "        config = opt2.config\n",
    "        mode = \"train\"\n",
    "        log_dir = 'log'\n",
    "        checkpoint = None\n",
    "        device_ids = model_no # {0,1}\n",
    "\n",
    "    with open(opt.config) as f:\n",
    "        config = yaml.load(f)\n",
    "\n",
    "    if opt.checkpoint is not None:\n",
    "        log_dir = os.path.join(*os.path.split(opt.checkpoint)[:-1])\n",
    "    else:\n",
    "        log_dir = os.path.join(opt.log_dir, os.path.basename(opt.config).split('.')[0])\n",
    "        log_dir += ' ' + strftime(\"%d_%m_%y_%H.%M.%S\", gmtime())\n",
    "\n",
    "    generator = OcclusionAwareGenerator(**config['model_params']['generator_params'],\n",
    "                                        **config['model_params']['common_params'])\n",
    "    discriminator = MultiScaleDiscriminator(**config['model_params']['discriminator_params'],\n",
    "                                            **config['model_params']['common_params'])\n",
    "    kp_detector = KPDetector(**config['model_params']['kp_detector_params'],\n",
    "                             **config['model_params']['common_params'])\n",
    "    \n",
    "    img_source_folder = f\"{config['dataset_params']['root_dir']}/test/\"\n",
    "\n",
    "    generator, kp_detector, discriminator, kp_refiner = \\\n",
    "    load_model(opt2, generator, kp_detector, discriminator,  \\\n",
    "               model_no=model_no)\n",
    "    if kp_refiner is None:\n",
    "        print(\"No kp_refiner\")\n",
    "    print(\"generator.dense_motion_network.kp_variance\", generator.dense_motion_network.kp_variance)\n",
    "    return generator, kp_detector, discriminator, kp_refiner, img_source_folder \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(source_name, driving_name, opt2,\n",
    "              generator, kp_detector, discriminator, kp_refiner, img_source_folder, model_no,\n",
    "              gen_anim=False, gen_anim_kp=False, graph_with_weight=True, gen_anim_kp_gif=True):\n",
    "    \n",
    "        \n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    kp_detector.eval()\n",
    "    if not kp_refiner is None: kp_refiner.eval()\n",
    "        \n",
    "    if opt2.cpu:\n",
    "        generator.to('cpu')\n",
    "        discriminator.to('cpu')\n",
    "        kp_detector.to('cpu')\n",
    "        if not kp_refiner is None: kp_refiner.to('cpu')\n",
    "        \n",
    "    source_video_pth = f\"{img_source_folder}{source_name}.gif\"\n",
    "    source_img_pth = f\"{img_save_folder}source_image_{source_name}.png\"\n",
    "    driving_video_pth = f\"{img_source_folder}{driving_name}.gif\"\n",
    "    save_name = f\"_sc{source_name}_dr{driving_name}_m{model_no}\"\n",
    "    result_video_save_pth = f\"{img_save_folder}result{save_name}.gif\"    \n",
    "\n",
    "    get_one_frame_in_gif_file(source_video_pth, \n",
    "                              source_img_pth, \n",
    "                              i=0)    \n",
    "\n",
    "    class opt3:\n",
    "        source_image = source_img_pth\n",
    "        driving_video = driving_video_pth\n",
    "        result_video = result_video_save_pth\n",
    "\n",
    "    source_image = imageio.imread(opt3.source_image)\n",
    "    reader = imageio.get_reader(opt3.driving_video)\n",
    "    fps = 15  #reader.get_meta_data()['fps']\n",
    "    driving_video = []\n",
    "    try:\n",
    "        for im in reader:\n",
    "            driving_video.append(im)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "    reader.close()\n",
    "\n",
    "    source_image = resize(source_image, (256, 256))[..., :3]\n",
    "    driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
    "    \n",
    "    print(\"make prediction...\")\n",
    "    predictions, masks, heatmaps, sparse_deformeds, kp_source_list, \\\n",
    "    kp_driving_list, kp_norm_list, adj_source, adj_driving, adj_weights_source, adj_weights_driving = \\\n",
    "        make_animation_split_kp(source_image, driving_video, generator, kp_detector, relative=opt2.relative, \\\n",
    "                                adapt_movement_scale=opt2.adapt_scale, cpu=opt2.cpu, stn=None, \\\n",
    "                                oval_heatmap=False, kp_refiner=kp_refiner)\n",
    "    \n",
    "        \n",
    "    #plot result\n",
    "    if gen_anim:\n",
    "        #plot result 動畫\n",
    "        print(\"save result animation...\")\n",
    "        imageio.mimsave(opt3.result_video, [img_as_ubyte(frame) for frame in predictions], fps=fps)\n",
    "        print(f\"save [{opt3.result_video}]!\")\n",
    "        \n",
    "    \n",
    "    if gen_anim_kp:\n",
    "        #plot heatmap all frame 動畫\n",
    "        print(\"save result animation with kp...\")\n",
    "        draw_heatmap_all_frame_w_graph_on_fig(\n",
    "            kp_detector, save_name, source_image, driving_video, predictions, masks, heatmaps, \\\n",
    "            sparse_deformeds, kp_source_list, kp_driving_list, \\\n",
    "            kp_norm_list, adj_source, adj_driving, adj_weights_source, adj_weights_driving, \\\n",
    "            save_pth=img_save_folder, fps=15, \n",
    "            graph_with_weight=graph_with_weight,\n",
    "            gen_kp_gif=gen_anim_kp_gif,\n",
    "        )\n",
    "        \n",
    "    return predictions, adj_weights_driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt2:\n",
    "    config = \"config/mgif-256-m2.yaml\"\n",
    "    checkpoints = [\n",
    "        '../../public/first-order-model/checkpoint/mgif-cpk.pth.tar',\n",
    "        'demo/202006221000/mgif_cpk_newattngraph_300.tar'\n",
    "    ]\n",
    "    cpu=True\n",
    "    relative = True\n",
    "    adapt_scale = True\n",
    "    find_best_frame = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_no:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No kp_refiner\n",
      "generator.dense_motion_network.kp_variance Parameter containing:\n",
      "tensor(0.0100, requires_grad=True)\n",
      "model_no:  1\n",
      "kp_variance:  tensor([0.0116])\n",
      "generator.dense_motion_network.kp_variance Parameter containing:\n",
      "tensor(0.0116, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "generator, kp_detector, discriminator, kp_refiner, img_source_folder  = build_model(opt2, model_no=0)\n",
    "generator_m, kp_detector_m, discriminator_m, kp_refiner_m, _ = build_model(opt2, model_no=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘demo/202006271600/’: File exists\n"
     ]
    }
   ],
   "source": [
    "source_name = \"00002\"\n",
    "driving_name = \"00001\"\n",
    "!mkdir \"demo/202006271600/\"\n",
    "img_save_folder = \"demo/202006271600/\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions, adj_weights_driving = \\\n",
    "inference(source_name, driving_name, opt2,\n",
    "          generator, kp_detector, discriminator, kp_refiner, img_source_folder, \n",
    "          model_no=0, gen_anim=False, gen_anim_kp=True, graph_with_weight=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions, adj_weights_driving = \\\n",
    "inference(source_name, driving_name, opt2,\n",
    "          generator_m, kp_detector_m, discriminator_m, kp_refiner_m, img_source_folder, \n",
    "          model_no=1, gen_anim=False, gen_anim_kp=True, graph_with_weight=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(11):  \n",
    "    r_ = torch.sum(adj_weights_driving>=(i/10))/np.product(adj_weights_driving.shape)\n",
    "    print(\"    #edge_weights(>={}): {:.2f} %\".format(i/10, r_*100)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "source_name: 00001, driving_name:00000\n",
      "Save file [demo/202006271600/source_image_00001.png]\n",
      "make prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(0,25):\n",
    "    st = time.time()\n",
    "    source_name, driving_name = str(i+1).zfill(5), str(i).zfill(5)\n",
    "    print(\"*\"*64+ f\"\\nsource_name: {source_name}, driving_name:{driving_name}\"  )\n",
    "    \n",
    "    predictions, adj_weights_driving = \\\n",
    "    inference(source_name, driving_name, opt2,\n",
    "              generator, kp_detector, discriminator, kp_refiner, img_source_folder, \n",
    "              model_no=0, gen_anim=True, gen_anim_kp=True, graph_with_weight=False, gen_anim_kp_gif=True)\n",
    "    \n",
    "    #if i<9: continue\n",
    "    predictions, adj_weights_driving = \\\n",
    "    inference(source_name, driving_name, opt2,\n",
    "              generator_m, kp_detector_m, discriminator_m, kp_refiner_m, img_source_folder, \n",
    "              model_no=1, gen_anim=True, gen_anim_kp=True, graph_with_weight=True, gen_anim_kp_gif=True)\n",
    "    \n",
    "    print(\"time cost: {:.2f}\".format(time.time()-st))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inference(source_name, driving_name, opt2,\n",
    "          generator, kp_detector, discriminator, kp_refiner, img_source_folder, \n",
    "          model_no=0, gen_anim=False, gen_anim_kp=True, graph_with_weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
